{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers=keras.layers\n",
    "mnist = keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,)\n",
      "0 255\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nwe do not need to convert numpy array to tensor. tensorflow do it internally. \\nx_train = tf.convert_to_tensor(x_train) \\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "print(x_train.shape, y_train.shape)\n",
    "# 60000 images with w*h=28*28 and 60000 labels\n",
    "print(x_train.min(), x_train.max())\n",
    "x_train = x_train.reshape(-1, 28*28).astype('float32')/255.0\n",
    "x_test = x_test.reshape(-1, 28*28).astype('float32')/255.0\n",
    "\n",
    "\"\"\"\n",
    "we do not need to convert numpy array to tensor. tensorflow do it internally. \n",
    "x_train = tf.convert_to_tensor(x_train) \n",
    "\"\"\"\n",
    "# x_train = tf.convert_to_tensor(x_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 229ms/step\n",
      "(20, 512)\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.Input(28*28),\n",
    "    layers.Dense(512, activation='relu', name='seq'),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dense(10) # output layer\n",
    "])\n",
    "\"\"\"Compile Technique\"\"\"\n",
    "# model= keras.Model(model.inputs,outputs=[model.layers[-2].output])\n",
    "model= keras.Model(model.inputs,outputs=[model.get_layer('seq').output])\n",
    "\n",
    "feature = model.predict(x_train[:20])\n",
    "print(feature.shape)\n",
    "\n",
    "model2 = keras.Sequential()\n",
    "model2.add(keras.Input(shape=(784)))\n",
    "model2.add(layers.Dense(512, activation=\"relu\"))\n",
    "model2.add(layers.Dense(256, activation=\"relu\", name=\"my_layer\"))\n",
    "model2.add(layers.Dense(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 - 1s - loss: 0.0890 - accuracy: 0.9760 - 1s/epoch - 9ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08898523449897766, 0.9760000109672546]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"from_logits = True: will add a softmax into the model then it will map the category\n",
    "\"\"\"\n",
    "\n",
    "model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer= keras.optimizers.Adam(learning_rate=.001),\n",
    "    metrics= 'accuracy'\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=5, verbose=0)\n",
    "model.evaluate(x_test, y_test, batch_size=64, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 784)]             0         \n",
      "                                                                 \n",
      " first_layer (Dense)         (None, 512)               401920    \n",
      "                                                                 \n",
      " second_layer (Dense)        (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 535,818\n",
      "Trainable params: 535,818\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Epoch 1/5\n",
      "938/938 - 11s - loss: 0.1997 - accuracy: 0.9399 - 11s/epoch - 12ms/step\n",
      "Epoch 2/5\n",
      "938/938 - 10s - loss: 0.0772 - accuracy: 0.9764 - 10s/epoch - 10ms/step\n",
      "Epoch 3/5\n",
      "938/938 - 11s - loss: 0.0524 - accuracy: 0.9833 - 11s/epoch - 12ms/step\n",
      "Epoch 4/5\n",
      "938/938 - 10s - loss: 0.0368 - accuracy: 0.9876 - 10s/epoch - 11ms/step\n",
      "Epoch 5/5\n",
      "938/938 - 10s - loss: 0.0287 - accuracy: 0.9911 - 10s/epoch - 11ms/step\n",
      "157/157 - 1s - loss: 0.0751 - accuracy: 0.9792 - 880ms/epoch - 6ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0750868022441864, 0.979200005531311]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def functional_model():\n",
    "    inputs =  keras.Input(28*28)\n",
    "    x = layers.Dense(512,activation='relu', name=\"first_layer\")(inputs)\n",
    "    x = layers.Dense(256, activation='relu', name=\"second_layer\")(x)\n",
    "    outputs = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    \"\"\"from_logits = True: will add a softmax into the model then it will map the category\n",
    "    \"\"\"\n",
    "    model.compile(\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "        optimizer= keras.optimizers.Adam(learning_rate=.001),\n",
    "        metrics= 'accuracy'\n",
    "    )\n",
    "    return model\n",
    "model = functional_model()\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=5, verbose=2)\n",
    "model.evaluate(x_test, y_test, batch_size=64, verbose=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
