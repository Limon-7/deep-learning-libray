{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential API:\n",
    "A Sequential model is appropriate for a plain stack of layers where each layer has exactly one input tensor and one output tensor.\n",
    "\n",
    "A Sequential model is not appropriate when:\n",
    "1. Your model has multiple inputs or multiple outputs\n",
    "2. Any of your layers has multiple inputs or multiple outputs\n",
    "3. You need to do layer sharing\n",
    "4. You want non-linear topology (e.g. a residual connection, a multi-branch model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers=keras.layers\n",
    "mnist = keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,)\n",
      "0 255\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nwe do not need to convert numpy array to tensor. tensorflow do it internally. \\nx_train = tf.convert_to_tensor(x_train) \\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "print(x_train.shape, y_train.shape)\n",
    "# 60000 images with w*h=28*28 and 60000 labels\n",
    "print(x_train.min(), x_train.max())\n",
    "x_train = x_train.reshape(-1, 28*28).astype('float32')/255.0\n",
    "x_test = x_test.reshape(-1, 28*28).astype('float32')/255.0\n",
    "\n",
    "\"\"\"\n",
    "we do not need to convert numpy array to tensor. tensorflow do it internally. \n",
    "x_train = tf.convert_to_tensor(x_train) \n",
    "\"\"\"\n",
    "# x_train = tf.convert_to_tensor(x_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.Input(28*28),\n",
    "    layers.Dense(512, activation='relu', name='seq'),\n",
    "    layers.Dense(256, activation='relu'),\n",
    "    layers.Dense(10) # output layer\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = keras.Sequential()\n",
    "model2.add(keras.Input(shape=(784)))\n",
    "model2.add(layers.Dense(512, activation=\"relu\"))\n",
    "model2.add(layers.Dense(256, activation=\"relu\", name=\"my_layer\"))\n",
    "model2.add(layers.Dense(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Debug Technique:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001D960AA8220> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 187ms/step\n",
      "(20, 256)\n"
     ]
    }
   ],
   "source": [
    "model= keras.Model(model.inputs,outputs=[model.layers[-2].output])\n",
    "# model= keras.Model(model.inputs,outputs=[model.get_layer('seq').output])\n",
    "\n",
    "feature = model.predict(x_train[:20])\n",
    "print(feature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 209ms/step\n",
      "(20, 784)\n",
      "(20, 512)\n",
      "(20, 256)\n"
     ]
    }
   ],
   "source": [
    "model= keras.Model(model.inputs,outputs=[layer.output for layer in model.layers])\n",
    "features = model.predict(x_train[:20])\n",
    "\n",
    "for feature in features:\n",
    "    print(feature.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 - 1s - loss: 0.0890 - accuracy: 0.9760 - 1s/epoch - 9ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.08898523449897766, 0.9760000109672546]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"from_logits = True: will add a softmax into the model then it will map the category\n",
    "\"\"\"\n",
    "\n",
    "model.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer= keras.optimizers.Adam(learning_rate=.001),\n",
    "    metrics= 'accuracy'\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=5, verbose=0)\n",
    "model.evaluate(x_test, y_test, batch_size=64, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 784)]             0         \n",
      "                                                                 \n",
      " first_layer (Dense)         (None, 512)               401920    \n",
      "                                                                 \n",
      " second_layer (Dense)        (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                2570      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 535,818\n",
      "Trainable params: 535,818\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Epoch 1/5\n",
      "938/938 - 11s - loss: 0.1997 - accuracy: 0.9399 - 11s/epoch - 12ms/step\n",
      "Epoch 2/5\n",
      "938/938 - 10s - loss: 0.0772 - accuracy: 0.9764 - 10s/epoch - 10ms/step\n",
      "Epoch 3/5\n",
      "938/938 - 11s - loss: 0.0524 - accuracy: 0.9833 - 11s/epoch - 12ms/step\n",
      "Epoch 4/5\n",
      "938/938 - 10s - loss: 0.0368 - accuracy: 0.9876 - 10s/epoch - 11ms/step\n",
      "Epoch 5/5\n",
      "938/938 - 10s - loss: 0.0287 - accuracy: 0.9911 - 10s/epoch - 11ms/step\n",
      "157/157 - 1s - loss: 0.0751 - accuracy: 0.9792 - 880ms/epoch - 6ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0750868022441864, 0.979200005531311]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def functional_model():\n",
    "    inputs =  keras.Input(28*28)\n",
    "    x = layers.Dense(512,activation='relu', name=\"first_layer\")(inputs)\n",
    "    x = layers.Dense(256, activation='relu', name=\"second_layer\")(x)\n",
    "    outputs = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    \"\"\"from_logits = True: will add a softmax into the model then it will map the category\n",
    "    \"\"\"\n",
    "    model.compile(\n",
    "        loss=keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "        optimizer= keras.optimizers.Adam(learning_rate=.001),\n",
    "        metrics= 'accuracy'\n",
    "    )\n",
    "    return model\n",
    "model = functional_model()\n",
    "print(model.summary())\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=5, verbose=2)\n",
    "model.evaluate(x_test, y_test, batch_size=64, verbose=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
