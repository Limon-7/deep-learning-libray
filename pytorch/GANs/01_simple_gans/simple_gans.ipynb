{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from pathlib import Path\n",
    "from  torchinfo import summary\n",
    "import os\n",
    "import torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "device= \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "lr=3e-4\n",
    "z_dim= 64\n",
    "img_dim = 28*28*1\n",
    "batch_size = 32\n",
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(WindowsPath('g:/Code/deep-learning-libray/pytorch/GANs/02_simple_gans'),\n",
       " WindowsPath('G:/Code/deep-learning-libray/pytorch/data'),\n",
       " WindowsPath('g:/Code/deep-learning-libray/pytorch/GANs/02_simple_gans'))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ROOT_DIR = Path.cwd()\n",
    "IMAGE_DIR=ROOT_DIR.parent.resolve().parent.resolve() / \"data\"\n",
    "# ROOT_DIR, IMAGE_DIR, Path.cwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, img_dim):\n",
    "        super().__init__()\n",
    "        self.disc= nn.Sequential(\n",
    "            nn.Linear(img_dim, 128),\n",
    "            nn.LeakyReLU(.1),\n",
    "            nn.Linear(128,1),\n",
    "            nn.Tanh(),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.disc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim, img_dim):\n",
    "        super().__init__()\n",
    "        self.disc= nn.Sequential(\n",
    "            nn.Linear(z_dim, 256),\n",
    "            nn.LeakyReLU(.1),\n",
    "            nn.Linear(256,img_dim),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.disc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc = Discriminator(img_dim).to(device)\n",
    "gen = Generator(z_dim, img_dim).to(device)\n",
    "fixed_noise = torch.randn((batch_size, z_dim)).to(device)\n",
    "transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,)),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.MNIST(root=IMAGE_DIR, transform=transforms, download=True)\n",
    "loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/20] Batch 0/1875                       Loss D: 0.7793, loss G: 0.6805\n",
      "Epoch [1/20] Batch 0/1875                       Loss D: 0.6231, loss G: 0.7990\n",
      "Epoch [2/20] Batch 0/1875                       Loss D: 0.5400, loss G: 0.9060\n",
      "Epoch [3/20] Batch 0/1875                       Loss D: 0.8133, loss G: 0.3133\n",
      "Epoch [4/20] Batch 0/1875                       Loss D: 0.8133, loss G: 0.3133\n",
      "Epoch [5/20] Batch 0/1875                       Loss D: 0.4111, loss G: 1.1707\n",
      "Epoch [6/20] Batch 0/1875                       Loss D: 0.8139, loss G: 0.3133\n",
      "Epoch [7/20] Batch 0/1875                       Loss D: 0.8133, loss G: 0.3133\n",
      "Epoch [8/20] Batch 0/1875                       Loss D: 0.8132, loss G: 0.3133\n",
      "Epoch [9/20] Batch 0/1875                       Loss D: 0.6138, loss G: 0.8440\n",
      "Epoch [10/20] Batch 0/1875                       Loss D: 0.8133, loss G: 0.3133\n",
      "Epoch [11/20] Batch 0/1875                       Loss D: 0.8133, loss G: 0.3133\n",
      "Epoch [12/20] Batch 0/1875                       Loss D: 0.8133, loss G: 0.3133\n",
      "Epoch [13/20] Batch 0/1875                       Loss D: 0.8133, loss G: 0.3133\n",
      "Epoch [14/20] Batch 0/1875                       Loss D: 0.8133, loss G: 0.3133\n",
      "Epoch [15/20] Batch 0/1875                       Loss D: 0.8133, loss G: 0.3133\n",
      "Epoch [16/20] Batch 0/1875                       Loss D: 0.8133, loss G: 0.3133\n",
      "Epoch [17/20] Batch 0/1875                       Loss D: 0.8133, loss G: 0.3133\n",
      "Epoch [18/20] Batch 0/1875                       Loss D: 0.8133, loss G: 0.3133\n",
      "Epoch [19/20] Batch 0/1875                       Loss D: 0.8133, loss G: 0.3133\n"
     ]
    }
   ],
   "source": [
    "opt_disc = optim.Adam(disc.parameters(), lr=lr)\n",
    "opt_gen = optim.Adam(gen.parameters(), lr=lr)\n",
    "criterion = nn.BCELoss()\n",
    "writer_fake = SummaryWriter(f\"{ROOT_DIR}/logs/fake\")\n",
    "writer_real = SummaryWriter(f\"{ROOT_DIR}/logs/real\")\n",
    "step = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_idx, (real, _) in enumerate(loader):\n",
    "        real = real.view(-1, 784).to(device)\n",
    "        batch_size = real.shape[0]\n",
    "\n",
    "        ### Train Discriminator: max log(D(x)) + log(1 - D(G(z)))\n",
    "        noise = torch.randn(batch_size, z_dim).to(device)\n",
    "        fake = gen(noise)\n",
    "        disc_real = disc(real).view(-1)\n",
    "        lossD_real = criterion(disc_real, torch.ones_like(disc_real))\n",
    "        disc_fake = disc(fake).view(-1)\n",
    "        lossD_fake = criterion(disc_fake, torch.zeros_like(disc_fake))\n",
    "        lossD = (lossD_real + lossD_fake) / 2\n",
    "        disc.zero_grad()\n",
    "        lossD.backward(retain_graph=True)\n",
    "        opt_disc.step()\n",
    "\n",
    "        ### Train Generator: min log(1 - D(G(z))) <-> max log(D(G(z))\n",
    "        # where the second option of maximizing doesn't suffer from\n",
    "        # saturating gradients\n",
    "        output = disc(fake).view(-1)\n",
    "        lossG = criterion(output, torch.ones_like(output))\n",
    "        gen.zero_grad()\n",
    "        lossG.backward()\n",
    "        opt_gen.step()\n",
    "\n",
    "        if batch_idx == 0:\n",
    "            print(\n",
    "                f\"Epoch [{epoch}/{num_epochs}] Batch {batch_idx}/{len(loader)} \\\n",
    "                      Loss D: {lossD:.4f}, loss G: {lossG:.4f}\"\n",
    "            )\n",
    "\n",
    "            with torch.no_grad():\n",
    "                fake = gen(fixed_noise).reshape(-1, 1, 28, 28)\n",
    "                data = real.reshape(-1, 1, 28, 28)\n",
    "                img_grid_fake = torchvision.utils.make_grid(fake, normalize=True)\n",
    "                img_grid_real = torchvision.utils.make_grid(data, normalize=True)\n",
    "\n",
    "                writer_fake.add_image(\n",
    "                    \"Mnist Fake Images\", img_grid_fake, global_step=step\n",
    "                )\n",
    "                writer_real.add_image(\n",
    "                    \"Mnist Real Images\", img_grid_real, global_step=step\n",
    "                )\n",
    "                step += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
