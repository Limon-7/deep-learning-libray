{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Import Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F  # Parameterless functions, like (some) activation functions\n",
    "import torch.nn as nn  # All neural network modules, nn.Linear, nn.Conv2d, BatchNorm, Loss functions\n",
    "import torch.optim as optim  # For all Optimization algorithms, SGD, Adam, etc.\n",
    "import torchvision.transforms as transforms  # Transformations we can perform on our dataset\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import (\n",
    "    Dataset,\n",
    "    DataLoader,\n",
    ")  # Gives easier dataset managment and creates mini batches\n",
    "from pathlib import Path\n",
    "from  torchinfo import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Config Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Hyperparameters\n",
    "in_channel = 3\n",
    "num_classes = 2\n",
    "learning_rate = 3e-4\n",
    "batch_size = 32\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data Processing Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv_path, root_dir, transform=None):\n",
    "        self.annotations = pd.read_csv(csv_path)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = os.path.join(self.root_dir, self.annotations.iloc[index, 0])\n",
    "        image = Image.open(img_path)\n",
    "        y_label = torch.tensor(int(self.annotations.iloc[index, 1]))\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return (image, y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_loader(csv_path, image_dir, transform = None, batch_size=64):\n",
    "    dataset =   CustomDataset(\n",
    "        csv_path=csv_path,\n",
    "        root_dir=image_dir,\n",
    "        transform=transform,\n",
    "    )\n",
    "    train_set, test_set = torch.utils.data.random_split(dataset, [5, 5])\n",
    "    train_loader = DataLoader(dataset=train_set, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(dataset=test_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    return (dataset, train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path\n",
    "current_working_dir = Path.cwd()\n",
    "csv_path = os.path.join(current_working_dir, \"data\", \"cats_dogs.csv\")\n",
    "image_dir = os.path.join(current_working_dir, \"data\", \"cats_dogs_resized\")\n",
    "# csv_path, cats_dogs_csv, image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((256, 256)),  # Resizes (32,32) to (36,36)\n",
    "        transforms.RandomCrop((224, 224)),  # Takes a random (32,32) crop\n",
    "        transforms.ColorJitter(brightness=0.5),  # Change brightness of image\n",
    "        transforms.RandomRotation(\n",
    "            degrees=45\n",
    "        ),  # Perhaps a random rotation from -45 to 45 degrees\n",
    "        transforms.RandomHorizontalFlip(\n",
    "            p=0.5\n",
    "        ),  # Flips the image horizontally with probability 0.5\n",
    "        transforms.RandomVerticalFlip(\n",
    "            p=0.05\n",
    "        ),  # Flips image vertically with probability 0.05\n",
    "        transforms.RandomGrayscale(p=0.2),  # Converts to grayscale with probability 0.2\n",
    "        transforms.ToTensor(),  # Finally converts PIL image to tensor so we can train w. pytorch\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "    ]\n",
    ")\n",
    "dataset, train_loader, test_loader = data_loader(\n",
    "    csv_path, image_dir, transform=to_transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_num=0\n",
    "for _ in range(10):\n",
    "    for img, label in dataset:\n",
    "        if label == 0:\n",
    "            name = \"cat\"\n",
    "        else:\n",
    "            name = \"dog\"\n",
    "        save_image(img, name + str(img_num)+'.png')\n",
    "        img_num += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Model Creation Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create CNN layer:\n",
    "class CNNNet(nn.Module):\n",
    "    def __init__(self, in_channels = 3, num_classes=10):\n",
    "        super(CNNNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels= 6, kernel_size=(5,5)) # output = (32-5+2*0)/1+1=28 -> [1, 6,28,28] parameter: 5^2*3*6+6 = 456 and colROw: 456*28*28\n",
    "        self.pool = nn.MaxPool2d(kernel_size=(2,2), stride=(2,2)) # output= 28-2/2+1=13+1= 14 => [1,6,14,14] params =null col_Row=null\n",
    "        self.conv2 = nn.Conv2d(in_channels = 6, out_channels= 16, kernel_size=(5,5)) # output = 14-5/1 + 1=10=>[1,16,10,10] parameter = 5^2*6*16+16 = 2416 and colRow = 2416*10*10\n",
    "        self.conv3 = nn.Conv2d(16,120,5)\n",
    "        self.flat = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(120,64)\n",
    "        self.fc2 = nn.Linear(64,num_classes)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.conv1(x)) # output = (32-5+2*0)/1+1=28 -> [1, 6,28,28] parameter: 5^2*3*6+6 = 456 and colROw: 456*28*28\n",
    "        x = self.pool(x)  # output= 28-2/2+1=13+1= 14 => [1,6,14,14] params =null col_Row=null\n",
    "        x = F.relu(self.conv2(x)) # output = 14-5/1 + 1=10=>[1,16,10,10] parameter = 5^2*6*16+16 = 2416 and colRow = 2416*10*10\n",
    "        x = self.pool(x) # output= 10-2/2+1= 4+1= 5 => [1,16,5,5] params =null col_Row=null\n",
    "        x = F.relu(self.conv3(x)) # output = 5-5/1 + 1= 1 =>[1,120,1,1]; parameter = 5^2*16*120+120 = 48120 and colRow = 48120*1*1\n",
    "        # x = x.reshape(x.shape[0], -1)\n",
    "        x = self.flat(x) # output= [1, 120*1*1]=>[1, 120]; params = null;  colRow =null\n",
    "        x = F.relu(self.fc1(x)) # output:[1, 64]; params: 120*64+64= 7744; colRow= 7744*1=7744\n",
    "        x = self.fc2(x) # output:[1, 10]; params: 64*10+10= 650; colRow =650\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train and Evaluation section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tain_nn(train_loader, model, criterion, optimizer):\n",
    "    for epoch in range(num_epochs):\n",
    "        losses = []\n",
    "\n",
    "        for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "            # Get data to cuda if possible\n",
    "            data = data.to(device=device)\n",
    "            targets = targets.to(device=device)\n",
    "\n",
    "            # forward\n",
    "            scores = model(data)\n",
    "            loss = criterion(scores, targets)\n",
    "\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            # backward\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            # gradient descent or adam step\n",
    "            optimizer.step()\n",
    "\n",
    "        print(f\"Cost at epoch {epoch} is {sum(losses)/len(losses)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(loader, model):\n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device)\n",
    "            y = y.to(device=device)\n",
    "\n",
    "            scores = model(x)\n",
    "            _, predictions = scores.max(1)\n",
    "            num_correct += (predictions == y).sum()\n",
    "            num_samples += predictions.size(0)\n",
    "\n",
    "        print(\n",
    "            f\"Got {num_correct} / {num_samples} with accuracy {float(num_correct)/float(num_samples)*100:.2f}\"\n",
    "        )\n",
    "\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Initialize model and trainning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "============================================================================================================================================\n",
       "Layer (type:depth-idx)                   Input Shape               Output Shape              Param #                   Mult-Adds\n",
       "============================================================================================================================================\n",
       "CNNNet                                   [1, 3, 32, 32]            [1, 10]                   --                        --\n",
       "├─Conv2d: 1-1                            [1, 3, 32, 32]            [1, 6, 28, 28]            456                       357,504\n",
       "├─MaxPool2d: 1-2                         [1, 6, 28, 28]            [1, 6, 14, 14]            --                        --\n",
       "├─Conv2d: 1-3                            [1, 6, 14, 14]            [1, 16, 10, 10]           2,416                     241,600\n",
       "├─MaxPool2d: 1-4                         [1, 16, 10, 10]           [1, 16, 5, 5]             --                        --\n",
       "├─Conv2d: 1-5                            [1, 16, 5, 5]             [1, 120, 1, 1]            48,120                    48,120\n",
       "├─Flatten: 1-6                           [1, 120, 1, 1]            [1, 120]                  --                        --\n",
       "├─Linear: 1-7                            [1, 120]                  [1, 64]                   7,744                     7,744\n",
       "├─Linear: 1-8                            [1, 64]                   [1, 10]                   650                       650\n",
       "============================================================================================================================================\n",
       "Total params: 59,386\n",
       "Trainable params: 59,386\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 0.66\n",
       "============================================================================================================================================\n",
       "Input size (MB): 0.01\n",
       "Forward/backward pass size (MB): 0.05\n",
       "Params size (MB): 0.24\n",
       "Estimated Total Size (MB): 0.30\n",
       "============================================================================================================================================"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CNNNet().to(device)\n",
    "summary(model, input_size=(1, 3, 32, 32), col_names= (\"input_size\", \"output_size\", \"num_params\", \"mult_adds\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Checking accuracy on Training Set\")\n",
    "check_accuracy(train_loader, model)\n",
    "\n",
    "print(\"Checking accuracy on Test Set\")\n",
    "check_accuracy(test_loader, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
