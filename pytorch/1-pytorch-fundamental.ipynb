{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Fundamental:\n",
    "<a id='h_cell'></a>\n",
    "Tensors are the central data abstraction in PyTorch. This interactive notebook provides an in-depth introduction to the `torch.Tensor` class. You can run this notebook locally, on [Colab](https://colab.research.google.com/), or on your preferred cloud service.\n",
    "\n",
    "|#NO|Topic|Status|\n",
    "|--:|:---          |--:|\n",
    "|01| [Terminology](#ter_cell)||\n",
    "|02| [Getting information](#gi_cell)|\n",
    "|03| [***Tensor Random***](#random_cell)|\n",
    "|04| [***Create Tensor***](#ctensor_cell)|\n",
    "|05| [Tensor Data Type](#dtype_cell)|\n",
    "|06| [***Math and Logic with Pytorch***](#math_cell)|\n",
    "|07| [***Manipulating Tensor Shape or Braodcasting***](#mts_cell)|\n",
    "|08| [***Array Accessing***](#aa_cell)|\n",
    "|09| [***Frequently used method***](#im_cell)|\n",
    "|10| [***Moving to GPU***](#gpu_cell)|\n",
    "|11| [***Numpy Bridge***](#npb_cell)|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [1. Terminology](#h_cell)\n",
    "<a id='ter_cell'></a>\n",
    "\n",
    "A brief note about tensors and their number of dimensions, and terminology:\n",
    "\n",
    "1. O-dimensional tensor called a \\*scaler.\n",
    "2. 1-dimensional tensor called a \\*vector.\n",
    "3. Likewise, a 2-dimensional tensor is often referred to as a \\*matrix.\n",
    "4. Anything with more than two dimensions is generally just called a tensor."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Scaler:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, torch.Size([]), 7, tensor(7), torch.Tensor)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = torch.tensor(7)\n",
    "scaler.ndim, scaler.shape, scaler.item(), scaler, type(scaler)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Vector:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([7, 8]), 1, torch.Size([2]))"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = torch.tensor([7, 8])\n",
    "print(type(vector))\n",
    "vector, vector.ndim, vector.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Here torch.Size([2]) means the vector has a shape 2 state that there are two items.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Matrix:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[ 7,  8],\n",
       "         [ 9, 10]]),\n",
       " torch.Size([2, 2]),\n",
       " 2,\n",
       " torch.int64)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Matrix\n",
    "MATRIX = torch.tensor([[7, 8], [9, 10]])\n",
    "print(type(MATRIX))\n",
    "MATRIX, MATRIX.shape, MATRIX.ndim, MATRIX.dtype"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **Tensor or Multi-dimentional:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[1, 2, 3],\n",
       "          [3, 6, 9],\n",
       "          [2, 4, 5]]]),\n",
       " torch.Size([1, 3, 3]),\n",
       " 3)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tensor\n",
    "TENSOR = torch.tensor([[[1, 2, 3], [3, 6, 9], [2, 4, 5]]])\n",
    "TENSOR, TENSOR.shape, TENSOR.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<function Tensor.size>, torch.Size([3, 2, 4]), 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor= torch.tensor([[[1, 2, 3,4], [4, 5, 6,4]], [[7, 8, 9,4], [10, 11, 12,4]], [[13, 14, 15,4], [16, 17, 18,4]]])\n",
    "tensor.size, tensor.shape, tensor.ndim"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [2. Getting Information](#h_cell)\n",
    "<a id='gi_cell'></a>\n",
    "\n",
    "1. type(x): type(tensor) will return the type of the tensor object.\n",
    "2. x.dtype: tensor.dtype will give you the data type.\n",
    "3. x.shape: tensor.shape will give you the shape of the tensor.\n",
    "4. x.size(): tensor.size() will give you the total number of elements.\n",
    "5. x.ndim: The ndim attribute of a PyTorch tensor returns the number of dimensions (rank) of the tensor.\n",
    "6. x.device: tensor.device will give you the device information.\n",
    "7. x.requires_grad: indicates whether the tensor requires gradient computation for backpropagation during training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "torch.int64\n",
      "torch.Size([2, 3])\n",
      "torch.Size([2, 3])\n",
      "2\n",
      "cpu\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor\n",
    "tensor = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "print(type(tensor))  # Get type of the tensor\n",
    "print(tensor.dtype)  # Get data type of the tensor\n",
    "print(tensor.shape)  # Get shape of the tensor\n",
    "print(tensor.size())  # Get total number of elements in the tensor\n",
    "print(tensor.ndim)  # Get number of dimensions of the tensor\n",
    "print(tensor.device)  # Get device information of the tensor\n",
    "print(tensor.requires_grad)  # Check if tensor requires gradient computation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [3. Random Tensors and Seeding:](#h_cell)\n",
    "<a id='random_cell'></a>\n",
    "\n",
    "Speaking of the random tensor, did you notice the call to `torch.manual_seed()` immediately preceding it? Initializing tensors, such as a model's learning weights, with random values is common but there are times - especially in research settings - where you'll want some assurance of the reproducibility of your results. Manually setting your random number generator's seed is the way to do this. Let's look more closely:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3, 3]),\n",
       " 3,\n",
       " tensor([[[0.2961, 0.5166, 0.2517],\n",
       "          [0.6886, 0.0740, 0.8665],\n",
       "          [0.1366, 0.1025, 0.1841]],\n",
       " \n",
       "         [[0.7264, 0.3153, 0.6871],\n",
       "          [0.0756, 0.1966, 0.3164],\n",
       "          [0.4017, 0.1186, 0.8274]]]),\n",
       " tensor([0.2961, 0.5166, 0.2517]),\n",
       " tensor(0.3164))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "torch_random = torch.rand([2, 3, 3], dtype=torch.float)  # same as torch.random(2,3,3)\n",
    "torch_random.shape, torch_random.ndim, torch_random, torch_random[0][0], torch_random[\n",
    "    1\n",
    "][1][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3126, 0.3791, 0.3087],\n",
      "        [0.0736, 0.4216, 0.0691]])\n",
      "tensor([[0.2332, 0.4047, 0.2162],\n",
      "        [0.9927, 0.4128, 0.5938]])\n",
      "tensor([[0.3126, 0.3791, 0.3087],\n",
      "        [0.0736, 0.4216, 0.0691]])\n",
      "tensor([[0.2332, 0.4047, 0.2162],\n",
      "        [0.9927, 0.4128, 0.5938]])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1729)\n",
    "random1 = torch.rand(2, 3)\n",
    "print(random1)\n",
    "\n",
    "random2 = torch.rand(2, 3)\n",
    "print(random2)\n",
    "\n",
    "torch.manual_seed(1729)\n",
    "random3 = torch.rand(2, 3)\n",
    "print(random3)\n",
    "\n",
    "random4 = torch.rand(2, 3)\n",
    "print(random4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What you should see above is that `random1` and `random3` carry identical values, as do `random2` and `random4`. Manually setting the RNG's seed resets it, so that identical computations depending on random number should, in most settings, provide identical results.\n",
    "\n",
    "For more information, see the [PyTorch documentation on reproducibility](https://pytorch.org/docs/stable/notes/randomness.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.3821, 0.6605, 0.8536, 0.5932],\n",
       "         [0.6367, 0.9826, 0.2745, 0.6584],\n",
       "         [0.2775, 0.8573, 0.8993, 0.0390]]),\n",
       " torch.float32)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_tensor = torch.rand(size=(3, 4))\n",
    "random_tensor, random_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[3.4346e-01, 1.1412e-01, 3.7161e-02],\n",
       "         [6.7748e-01, 9.5072e-01, 5.7306e-01],\n",
       "         [8.2716e-01, 3.6313e-01, 9.8644e-01],\n",
       "         [3.5969e-01, 6.9106e-01, 6.5847e-01],\n",
       "         [7.8675e-01, 5.9714e-01, 7.1090e-01],\n",
       "         [5.4176e-01, 6.0740e-01, 6.1512e-01],\n",
       "         [2.6526e-01, 2.3738e-01, 8.3565e-01],\n",
       "         [5.8544e-01, 8.6992e-01, 6.1827e-02],\n",
       "         [6.7257e-01, 8.0526e-01, 5.2741e-01],\n",
       "         [8.4499e-02, 6.1248e-01, 9.6163e-01],\n",
       "         [1.5855e-01, 2.4873e-01, 9.1681e-01],\n",
       "         [2.4133e-01, 6.4243e-01, 6.3256e-01],\n",
       "         [5.2445e-01, 5.7729e-01, 4.5339e-01],\n",
       "         [4.8180e-01, 3.3952e-02, 7.6372e-01],\n",
       "         [9.5316e-01, 8.2589e-01, 2.0838e-01],\n",
       "         [5.8818e-01, 3.2247e-01, 6.9899e-01],\n",
       "         [2.4950e-01, 4.5095e-01, 3.6715e-02],\n",
       "         [4.2967e-01, 8.1858e-01, 5.4694e-01],\n",
       "         [2.7438e-01, 1.7958e-01, 2.2569e-01],\n",
       "         [7.2946e-01, 7.3824e-01, 3.0567e-01],\n",
       "         [6.7375e-01, 9.6540e-01, 1.4697e-01],\n",
       "         [3.2119e-01, 4.3206e-02, 5.4639e-01],\n",
       "         [9.0337e-01, 8.0332e-01, 9.4312e-01],\n",
       "         [7.4361e-01, 6.6159e-01, 5.3620e-01],\n",
       "         [9.7702e-01, 4.9243e-01, 3.7196e-01],\n",
       "         [1.0856e-01, 5.6053e-01, 9.5245e-01],\n",
       "         [4.3516e-01, 2.4382e-01, 6.7555e-01],\n",
       "         [7.3552e-01, 7.6847e-01, 8.2162e-01],\n",
       "         [3.6740e-01, 9.9667e-01, 2.2934e-01],\n",
       "         [9.5703e-01, 8.6101e-01, 7.1215e-02],\n",
       "         [9.1699e-01, 1.9933e-01, 8.9148e-01],\n",
       "         [1.8175e-01, 9.7007e-01, 4.9569e-01],\n",
       "         [8.8066e-01, 1.9065e-01, 2.4010e-01],\n",
       "         [3.8256e-01, 4.8684e-01, 2.1438e-01],\n",
       "         [7.0233e-01, 6.9275e-01, 2.2442e-01],\n",
       "         [5.2285e-01, 3.0299e-01, 4.2039e-01],\n",
       "         [8.8575e-01, 4.0712e-01, 5.9759e-01],\n",
       "         [4.0917e-01, 8.9493e-01, 1.1875e-01],\n",
       "         [6.6380e-01, 4.2144e-01, 4.9283e-01],\n",
       "         [4.2250e-02, 1.9918e-01, 9.2250e-01],\n",
       "         [3.9480e-01, 7.9678e-01, 2.5571e-01],\n",
       "         [5.0310e-01, 9.3774e-01, 7.0605e-01],\n",
       "         [9.6089e-01, 1.0127e-01, 1.0390e-01],\n",
       "         [6.0043e-01, 5.0583e-03, 6.8435e-01],\n",
       "         [4.2219e-01, 2.4348e-01, 5.7534e-01],\n",
       "         [9.6745e-01, 8.0386e-01, 7.8101e-01],\n",
       "         [4.1427e-01, 8.2883e-02, 3.9055e-02],\n",
       "         [7.6278e-01, 1.6024e-01, 2.2605e-01],\n",
       "         [4.4341e-01, 4.8009e-01, 7.1044e-01],\n",
       "         [8.4789e-01, 4.5487e-01, 1.1445e-01],\n",
       "         [6.3913e-01, 5.9509e-01, 5.8914e-02],\n",
       "         [4.1162e-01, 3.2944e-01, 7.1955e-01],\n",
       "         [1.1484e-01, 2.1667e-01, 7.8077e-01],\n",
       "         [8.4280e-01, 4.8702e-01, 8.0601e-01],\n",
       "         [7.4119e-01, 7.3229e-02, 9.1063e-01],\n",
       "         [3.9827e-01, 3.2731e-01, 5.6107e-01],\n",
       "         [5.8378e-01, 9.9705e-01, 1.8508e-01],\n",
       "         [3.3224e-01, 9.8765e-01, 2.4673e-01],\n",
       "         [3.6421e-01, 5.4518e-01, 9.9296e-01],\n",
       "         [4.8261e-02, 3.2466e-01, 7.4454e-01],\n",
       "         [5.0777e-01, 8.6174e-01, 8.8193e-01],\n",
       "         [5.7600e-01, 5.9802e-01, 5.2537e-01],\n",
       "         [3.8474e-01, 7.8709e-01, 5.4318e-01],\n",
       "         [7.9544e-01, 4.6931e-01, 2.3194e-01],\n",
       "         [1.8686e-01, 4.2070e-01, 9.8543e-01],\n",
       "         [9.2127e-02, 6.2073e-01, 7.6060e-01],\n",
       "         [2.2675e-01, 1.5049e-01, 2.2211e-01],\n",
       "         [6.4721e-01, 8.1263e-01, 2.8788e-01],\n",
       "         [5.4043e-01, 3.3445e-01, 6.9890e-02],\n",
       "         [5.5919e-01, 7.3276e-01, 9.6423e-01],\n",
       "         [1.4009e-01, 1.9968e-01, 9.6606e-01],\n",
       "         [2.1776e-01, 1.2049e-01, 6.1614e-01],\n",
       "         [4.0461e-01, 2.0779e-01, 7.8645e-01],\n",
       "         [6.2915e-01, 7.4800e-01, 9.0612e-01],\n",
       "         [2.7967e-01, 3.5208e-01, 8.7079e-01],\n",
       "         [4.0179e-01, 7.6492e-01, 3.4246e-01],\n",
       "         [5.4887e-01, 9.2929e-02, 7.3900e-01],\n",
       "         [2.9981e-01, 4.4845e-01, 5.1913e-01],\n",
       "         [3.2042e-01, 6.4359e-01, 5.0002e-01],\n",
       "         [4.0127e-01, 1.5496e-01, 7.0536e-01],\n",
       "         [1.8251e-01, 4.0096e-01, 7.9377e-01],\n",
       "         [1.2915e-01, 1.7277e-01, 4.1353e-01],\n",
       "         [9.2765e-01, 9.5865e-01, 3.3394e-01],\n",
       "         [3.8546e-01, 4.5492e-01, 2.6878e-01],\n",
       "         [4.8051e-01, 2.9401e-01, 9.9437e-01],\n",
       "         [8.1795e-01, 8.2696e-01, 9.5319e-01],\n",
       "         [5.0331e-01, 6.6932e-01, 3.9150e-01],\n",
       "         [3.8283e-01, 2.2582e-01, 2.8815e-01],\n",
       "         [7.1362e-01, 6.0694e-01, 1.5948e-01],\n",
       "         [1.7657e-01, 7.7609e-03, 8.7566e-01],\n",
       "         [7.8525e-01, 7.3040e-01, 8.6333e-01],\n",
       "         [8.5646e-01, 4.1732e-01, 9.1775e-01],\n",
       "         [6.7344e-01, 9.2335e-01, 2.5294e-01],\n",
       "         [9.1567e-01, 6.1929e-01, 5.4559e-01],\n",
       "         [3.5158e-01, 6.8214e-01, 8.4694e-01],\n",
       "         [7.7653e-02, 6.8378e-01, 3.2590e-01],\n",
       "         [7.7757e-01, 9.4526e-01, 5.0838e-01],\n",
       "         [3.0531e-01, 8.6310e-01, 4.5057e-01],\n",
       "         [8.6989e-02, 9.1982e-01, 6.6554e-01],\n",
       "         [4.7064e-01, 5.3264e-01, 8.7482e-01],\n",
       "         [3.7589e-01, 1.4800e-01, 2.7555e-01],\n",
       "         [1.9407e-01, 8.9750e-01, 1.1325e-01],\n",
       "         [3.2876e-01, 2.6124e-01, 5.3191e-01],\n",
       "         [6.1223e-01, 4.3256e-01, 8.4552e-01],\n",
       "         [8.2048e-01, 8.4185e-01, 7.1921e-01],\n",
       "         [9.3957e-01, 2.8584e-01, 8.8324e-01],\n",
       "         [6.0993e-01, 3.1624e-01, 7.8352e-01],\n",
       "         [7.9984e-01, 5.3161e-02, 7.1580e-01],\n",
       "         [9.4043e-01, 7.3222e-01, 3.5215e-01],\n",
       "         [8.4625e-01, 6.7781e-01, 6.4534e-01],\n",
       "         [7.6947e-02, 9.3381e-01, 5.5293e-01],\n",
       "         [4.0195e-01, 1.4143e-01, 1.9042e-01],\n",
       "         [7.5992e-01, 5.9235e-01, 1.1818e-01],\n",
       "         [2.4000e-01, 3.8789e-01, 4.8158e-01],\n",
       "         [4.5989e-01, 7.9967e-01, 5.0927e-01],\n",
       "         [6.0375e-01, 3.5443e-02, 5.7351e-01],\n",
       "         [1.0083e-01, 7.7552e-01, 1.1050e-01],\n",
       "         [3.7279e-01, 9.6000e-01, 7.8193e-01],\n",
       "         [7.4402e-02, 7.6281e-01, 1.4268e-01],\n",
       "         [9.6241e-01, 1.6879e-02, 2.8789e-01],\n",
       "         [4.4963e-01, 6.4486e-01, 4.4697e-01],\n",
       "         [8.7271e-01, 6.8619e-01, 1.6117e-01],\n",
       "         [9.9912e-01, 3.9795e-01, 6.7413e-01],\n",
       "         [9.0548e-01, 8.7435e-01, 6.8873e-01],\n",
       "         [7.1872e-01, 1.4496e-01, 2.8812e-01],\n",
       "         [6.5207e-02, 7.5228e-01, 1.9549e-02],\n",
       "         [4.5945e-01, 7.5059e-01, 1.6572e-01],\n",
       "         [2.9981e-01, 3.9595e-01, 7.9538e-01],\n",
       "         [3.0702e-01, 4.0488e-01, 7.1588e-01],\n",
       "         [2.7350e-01, 7.2220e-01, 3.7404e-01],\n",
       "         [1.9723e-01, 1.7626e-02, 4.2784e-01],\n",
       "         [7.2589e-01, 8.3745e-01, 3.3683e-01],\n",
       "         [9.2218e-01, 3.1427e-01, 2.2675e-01],\n",
       "         [5.5797e-01, 1.8560e-01, 8.9932e-01],\n",
       "         [6.3164e-01, 6.5299e-01, 1.1712e-01],\n",
       "         [9.5782e-01, 1.8166e-01, 5.6394e-01],\n",
       "         [6.7798e-01, 1.0008e-01, 2.6145e-01],\n",
       "         [9.2146e-01, 9.4514e-01, 3.9298e-02],\n",
       "         [4.2389e-01, 2.9263e-01, 8.0361e-01],\n",
       "         [5.3882e-01, 3.9419e-01, 5.9470e-01],\n",
       "         [2.8465e-01, 1.5803e-01, 7.7588e-01],\n",
       "         [8.2317e-01, 6.6461e-02, 4.0639e-01],\n",
       "         [5.4623e-01, 6.1952e-01, 5.1653e-01],\n",
       "         [8.9132e-01, 8.7868e-01, 4.1978e-01],\n",
       "         [1.6856e-01, 2.5064e-01, 8.5326e-01],\n",
       "         [1.7566e-01, 1.3009e-02, 8.2044e-01],\n",
       "         [9.9709e-01, 3.5767e-01, 2.9695e-01],\n",
       "         [3.3759e-01, 3.3274e-03, 6.7987e-01],\n",
       "         [8.3640e-01, 9.2058e-01, 1.5627e-01],\n",
       "         [4.3612e-01, 8.6260e-01, 3.5655e-02],\n",
       "         [5.2161e-01, 5.7188e-01, 8.9349e-02],\n",
       "         [5.0879e-02, 8.5292e-01, 4.5611e-01],\n",
       "         [2.3208e-01, 2.5792e-02, 4.6942e-01],\n",
       "         [1.8363e-01, 5.3722e-01, 3.7536e-02],\n",
       "         [2.2508e-01, 2.0874e-01, 9.8483e-01],\n",
       "         [6.5575e-01, 9.3905e-01, 9.2567e-01],\n",
       "         [3.6171e-01, 6.6303e-01, 2.3761e-01],\n",
       "         [4.4856e-01, 4.1340e-02, 5.4071e-01],\n",
       "         [8.4344e-01, 9.7554e-01, 3.2427e-01],\n",
       "         [7.3362e-01, 8.5162e-01, 9.5091e-01],\n",
       "         [2.8177e-01, 8.1306e-01, 7.4193e-01],\n",
       "         [6.5446e-01, 3.7960e-01, 9.2098e-01],\n",
       "         [8.1128e-01, 6.3741e-01, 3.7966e-01],\n",
       "         [2.8146e-01, 2.3881e-02, 3.1693e-01],\n",
       "         [4.2599e-01, 4.1056e-01, 7.0321e-01],\n",
       "         [3.7931e-02, 7.3686e-01, 6.7712e-01],\n",
       "         [4.1787e-01, 6.6398e-01, 9.1463e-01],\n",
       "         [6.2543e-03, 8.3603e-01, 9.8348e-01],\n",
       "         [9.8615e-01, 3.3057e-01, 5.1326e-02],\n",
       "         [1.9455e-01, 8.6992e-01, 4.0828e-01],\n",
       "         [4.5755e-01, 3.6490e-01, 6.3291e-01],\n",
       "         [9.7015e-01, 5.7466e-02, 5.2432e-01],\n",
       "         [1.8345e-01, 8.5964e-01, 1.2760e-01],\n",
       "         [7.8793e-01, 7.5202e-01, 9.9456e-03],\n",
       "         [4.8293e-01, 2.8732e-01, 4.9528e-01],\n",
       "         [9.3593e-01, 7.0136e-01, 6.7470e-02],\n",
       "         [7.6241e-01, 7.3791e-01, 6.5778e-01],\n",
       "         [5.9653e-01, 4.5098e-01, 5.0917e-01],\n",
       "         [6.1074e-02, 1.8968e-02, 1.7953e-01],\n",
       "         [7.6166e-01, 6.4889e-01, 3.1163e-01],\n",
       "         [8.1234e-01, 3.0768e-01, 8.7146e-01],\n",
       "         [4.8995e-01, 6.2122e-02, 6.7914e-01],\n",
       "         [8.0468e-01, 7.6981e-01, 4.2869e-01],\n",
       "         [1.5186e-01, 5.5514e-01, 2.4495e-01],\n",
       "         [6.2973e-02, 9.8314e-02, 3.3082e-01],\n",
       "         [5.2536e-01, 3.0159e-01, 1.1493e-01],\n",
       "         [3.8929e-01, 7.5679e-01, 7.6923e-01],\n",
       "         [9.3637e-01, 9.5486e-01, 3.3503e-01],\n",
       "         [3.5836e-01, 2.5122e-01, 8.7182e-01],\n",
       "         [8.0235e-01, 3.6323e-01, 6.7070e-01],\n",
       "         [1.8755e-03, 7.2773e-01, 5.1434e-01],\n",
       "         [2.6137e-01, 9.3304e-01, 5.0330e-01],\n",
       "         [7.3172e-01, 8.6513e-01, 3.8944e-01],\n",
       "         [2.8793e-01, 8.3030e-01, 5.0448e-03],\n",
       "         [6.7001e-01, 9.2622e-01, 6.9657e-01],\n",
       "         [1.2715e-02, 5.4820e-01, 4.7383e-01],\n",
       "         [1.2996e-01, 9.6605e-01, 8.5741e-01],\n",
       "         [6.2673e-01, 5.8522e-01, 6.9414e-01],\n",
       "         [6.9567e-01, 6.0105e-04, 1.9287e-01],\n",
       "         [6.6996e-01, 6.1078e-02, 5.7016e-01],\n",
       "         [8.7006e-01, 1.6151e-01, 3.7457e-01],\n",
       "         [4.2754e-01, 1.8486e-01, 1.5516e-02],\n",
       "         [9.1008e-01, 4.2556e-01, 7.1674e-01],\n",
       "         [1.9568e-01, 8.3371e-01, 5.9868e-02],\n",
       "         [4.0508e-01, 3.2848e-01, 4.5066e-01],\n",
       "         [9.8739e-01, 1.1714e-01, 8.2527e-01],\n",
       "         [8.9056e-01, 8.2478e-01, 2.1209e-01],\n",
       "         [6.1390e-01, 3.3175e-01, 1.4040e-01],\n",
       "         [7.7254e-01, 9.9590e-01, 1.0300e-02],\n",
       "         [5.9743e-01, 3.1256e-01, 6.9075e-01],\n",
       "         [9.6613e-01, 9.3414e-01, 5.3711e-01],\n",
       "         [9.7677e-01, 2.0087e-01, 4.7776e-01],\n",
       "         [3.4513e-01, 1.5585e-01, 8.6202e-02],\n",
       "         [6.4009e-01, 4.5032e-01, 8.8635e-01],\n",
       "         [8.8744e-01, 1.9814e-01, 2.0934e-01],\n",
       "         [7.8420e-01, 4.0591e-01, 2.4507e-01],\n",
       "         [7.6650e-01, 3.5606e-01, 7.8523e-02],\n",
       "         [7.4179e-02, 9.7020e-01, 1.5920e-01],\n",
       "         [8.0801e-01, 6.0049e-01, 2.2203e-01],\n",
       "         [2.6468e-01, 8.5092e-01, 1.3346e-01],\n",
       "         [2.9648e-01, 1.2862e-01, 4.4340e-02],\n",
       "         [8.0430e-01, 4.8229e-01, 6.5824e-01],\n",
       "         [3.6234e-01, 7.2127e-01, 2.5951e-01],\n",
       "         [3.9256e-01, 6.0473e-01, 2.3793e-01],\n",
       "         [4.2441e-02, 8.4363e-02, 4.3013e-01],\n",
       "         [9.0728e-01, 4.9451e-01, 5.7843e-01],\n",
       "         [9.9232e-01, 1.9430e-01, 2.3035e-01],\n",
       "         [8.3386e-01, 2.2971e-01, 3.0433e-01],\n",
       "         [2.1544e-01, 6.8960e-01, 7.8561e-01],\n",
       "         [9.0738e-01, 8.3326e-01, 2.1815e-01],\n",
       "         [8.0832e-01, 5.0361e-02, 3.8821e-01],\n",
       "         [1.1244e-01, 1.3342e-01, 1.9353e-01],\n",
       "         [4.0553e-01, 8.3956e-01, 5.2301e-01],\n",
       "         [8.1742e-01, 1.2041e-01, 6.5735e-01],\n",
       "         [1.7501e-01, 9.8137e-02, 7.3144e-01],\n",
       "         [2.3173e-01, 4.4481e-01, 1.1305e-01],\n",
       "         [2.3873e-01, 2.5764e-01, 9.5605e-01],\n",
       "         [2.2970e-01, 1.3036e-01, 2.2469e-01],\n",
       "         [5.2798e-01, 4.0339e-01, 7.0086e-01],\n",
       "         [8.6573e-01, 5.2253e-01, 3.5149e-01],\n",
       "         [2.6057e-01, 5.2500e-01, 9.4335e-01],\n",
       "         [7.3266e-02, 6.6294e-01, 5.0632e-01],\n",
       "         [9.7710e-01, 1.5479e-01, 4.2307e-01],\n",
       "         [2.3605e-01, 8.7083e-02, 4.1881e-02]]),\n",
       " torch.Size([224, 244, 3]),\n",
       " 3,\n",
       " torch.float32,\n",
       " torch.Tensor)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## image shape of [224, 224, 3] ([height, width, color_channels]).\n",
    "image = torch.rand(224, 244, 3)\n",
    "image[1], image.shape, image.ndim, image.dtype, type(image)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [4. Creating Tensors](#h_cell)\n",
    "<a id='ctensor_cell'></a>\n",
    "\n",
    "1. `torch.tensor()`: create a tensor object.\n",
    "2. `torch.random()`: create a random tensor with given shape.\n",
    "3. `torch.ones()`: create a tensor with one.\n",
    "4. `torch.zeors()`: create a tensor with $0$\n",
    "5. `torch.arange(start, end, step)`:\n",
    "6. `torch.empty()`: The `torch.empty()` call allocates memory for the tensor, but does not initialize it with any values - so what you're seeing is whatever was in memory at the time of allocation.\n",
    "7. ``torch.*_like(x)`: Often, when you're performing operations on two or more tensors, they will need to be of the same _shape_ - that is, having the same number of dimensions and the same number of cells in each dimension. For that, we have the `torch.*_like()` methods.\n",
    "   1. `torch.empty_like(x):`\n",
    "   2. `torch.zeros_like(x):`\n",
    "   3. `torch.empty_like(x):`\n",
    "   4. `torch.rand_like()`:\n",
    "\n",
    "_Note: `torch.tensor()` creates a copy of the data._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]]) torch.Size([2, 3])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[0.3126, 0.3791, 0.3087],\n",
      "        [0.0736, 0.4216, 0.0691]])\n",
      "<class 'torch.Tensor'>\n",
      "tensor([[0.0000, 1.8750, 0.0000, 1.8750],\n",
      "        [0.0000, 1.8750, 0.0000, 1.8750],\n",
      "        [0.0000, 1.8750, 0.0000, 1.8750]])\n"
     ]
    }
   ],
   "source": [
    "zeros = torch.zeros(2,3)\n",
    "print(zeros, zeros.shape)\n",
    "\n",
    "ones = torch.ones(2, 3)\n",
    "print(ones)\n",
    "\n",
    "torch.manual_seed(1729)\n",
    "random = torch.rand(2, 3)\n",
    "print(random)\n",
    "\n",
    "x = torch.empty(size=(3, 4))\n",
    "print(type(x))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.arrange():\n",
    "zero_to_ten = torch.arange(start=0, end=10, step=1)\n",
    "zero_to_ten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 3])\n",
      "tensor([[[0., 0., 0.],\n",
      "         [0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.],\n",
      "         [0., 0., 0.]]])\n",
      "torch.Size([2, 2, 3])\n",
      "tensor([[[0., 0., 0.],\n",
      "         [0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.],\n",
      "         [0., 0., 0.]]])\n",
      "torch.Size([2, 2, 3])\n",
      "tensor([[[0., 0., 0.],\n",
      "         [0., 0., 0.]],\n",
      "\n",
      "        [[0., 0., 0.],\n",
      "         [0., 0., 0.]]])\n",
      "torch.Size([2, 2, 3])\n",
      "tensor([[[1., 1., 1.],\n",
      "         [1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1.],\n",
      "         [1., 1., 1.]]])\n",
      "torch.Size([2, 2, 3])\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "## torch.*_like()\n",
    "x = torch.empty(2, 2, 3)\n",
    "print(x.shape)\n",
    "print(x)\n",
    "\n",
    "empty_like_x = torch.empty_like(x)\n",
    "print(empty_like_x.shape)\n",
    "print(empty_like_x)\n",
    "\n",
    "zeros_like_x = torch.zeros_like(x)\n",
    "print(zeros_like_x.shape)\n",
    "print(zeros_like_x)\n",
    "\n",
    "ones_like_x = torch.ones_like(x)\n",
    "print(ones_like_x.shape)\n",
    "print(ones_like_x)\n",
    "\n",
    "rand_like_x = torch.rand_like(x)\n",
    "print(rand_like_x.shape)\n",
    "print(type(rand_like_x))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's unpack what we just did:\n",
    "\n",
    "- The tensor itself is 2-dimensional, having 3 rows and 4 columns.\n",
    "- The type of the object returned is `torch.Tensor`, which is an alias for `torch.FloatTensor`; by default, PyTorch tensors are populated with 32-bit floating point numbers. (More on data types below.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3.1416, 2.7183],\n",
      "        [1.6180, 0.0073]])\n",
      "tensor([ 2,  3,  5,  7, 11, 13, 17, 19])\n",
      "tensor([[2, 4, 6],\n",
      "        [3, 6, 9]])\n"
     ]
    }
   ],
   "source": [
    "some_constants = torch.tensor([[3.1415926, 2.71828], [1.61803, 0.0072897]])\n",
    "print(some_constants)\n",
    "\n",
    "some_integers = torch.tensor((2, 3, 5, 7, 11, 13, 17, 19))\n",
    "print(some_integers)\n",
    "\n",
    "more_integers = torch.tensor(((2, 4, 6), [3, 6, 9]))\n",
    "print(more_integers)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [5. Tensor Data type:](#h_cell)\n",
    "<a id='dtype_cell'></a>\n",
    "\n",
    "Setting the datatype of a tensor is possible a couple of ways:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 1, 1],\n",
       "         [1, 1, 1]], dtype=torch.int16),\n",
       " tensor([[17.3151, 14.5980,  6.0404],\n",
       "         [18.0429,  7.2532, 19.6519]], dtype=torch.float64),\n",
       " tensor([[17, 14,  6],\n",
       "         [18,  7, 19]], dtype=torch.int32))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones((2, 3), dtype=torch.int16)\n",
    "\n",
    "b = torch.rand((2, 3), dtype=torch.float64) * 20.0\n",
    "\n",
    "c = b.to(torch.int32)\n",
    "\n",
    "a, b, c"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest way to set the underlying data type of a tensor is with an optional argument at creation time. In the first line of the cell above, we set `dtype=torch.int16` for the tensor `a`. When we print `a`, we can see that it's full of `1` rather than `1.` - Python's subtle cue that this is an integer type rather than floating point.\n",
    "\n",
    "Another thing to notice about printing `a` is that, unlike when we left `dtype` as the default (32-bit floating point), printing the tensor also specifies its `dtype`.\n",
    "\n",
    "You may have also spotted that we went from specifying the tensor's shape as a series of integer arguments, to grouping those arguments in a tuple. This is not strictly necessary - PyTorch will take a series of initial, unlabeled integer arguments as a tensor shape - but when adding the optional arguments, it can make your intent more readable.\n",
    "\n",
    "The other way to set the datatype is with the `.to()` method. In the cell above, we create a random floating point tensor `b` in the usual way. Following that, we create `c` by converting `b` to a 32-bit integer with the `.to()` method. Note that `c` contains all the same values as `b`, but truncated to integers.\n",
    "\n",
    "Available data types include:\n",
    "\n",
    "- `torch.bool`\n",
    "- `torch.int8`\n",
    "- `torch.uint8`\n",
    "- `torch.int16`\n",
    "- `torch.int32`\n",
    "- `torch.int64`\n",
    "- `torch.half`\n",
    "- `torch.float`\n",
    "- `torch.double`\n",
    "- `torch.bfloat`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3]), torch.float32, device(type='cpu'))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Default datatype for tensors is float32\n",
    "float_32_tensor = torch.tensor(\n",
    "    [3.0, 6.0, 9.0],\n",
    "    dtype=None,  # defaults to None, which is torch.float32 or whatever datatype is passed\n",
    "    device=None,  # defaults to None, which uses the default tensor type\n",
    "    requires_grad=False,\n",
    ")  # if True, operations performed on the tensor are recorded\n",
    "\n",
    "float_32_tensor.shape, float_32_tensor.dtype, float_32_tensor.device"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [6. Math & Logic with PyTorch](#h_cell)\n",
    "<a id='math_cell'></a>\n",
    "\n",
    "Now that you know some of the ways to create a tensor... what can you do with them?\n",
    "\n",
    "Let's look at basic arithmetic first, and how tensors interact with simple scalars:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[101., 101.],\n",
      "        [101., 101.]])\n",
      "tensor([[2., 2.],\n",
      "        [2., 2.]])\n",
      "tensor([[3., 3.],\n",
      "        [3., 3.]])\n",
      "tensor([[4., 4.],\n",
      "        [4., 4.]])\n",
      "tensor([[1.4142, 1.4142],\n",
      "        [1.4142, 1.4142]])\n"
     ]
    }
   ],
   "source": [
    "ones = torch.zeros(2, 2) + 1  # addition ones.add()\n",
    "ones = ones.add(100)\n",
    "twos = torch.ones(2, 2) * 2  # multiplication\n",
    "threes = (torch.ones(2, 2) * 7 - 1) / 2  # complex operation\n",
    "fours = twos**2  # squre\n",
    "sqrt2s = twos**0.5  ## squre root\n",
    "\n",
    "print(ones)\n",
    "print(twos)\n",
    "print(threes)\n",
    "print(fours)\n",
    "print(sqrt2s)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar operations between two tensors also behave like you'd intuitively expect:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.,  4.],\n",
      "        [ 8., 16.]])\n",
      "tensor([[105., 105.],\n",
      "        [105., 105.]])\n",
      "tensor([[12., 12.],\n",
      "        [12., 12.]])\n"
     ]
    }
   ],
   "source": [
    "powers2 = twos ** torch.tensor([[1, 2], [3, 4]])\n",
    "print(powers2)\n",
    "\n",
    "fives = ones + fours\n",
    "print(fives)\n",
    "\n",
    "dozens = threes * fours  # element wise multiplication\n",
    "print(dozens)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Matrix multiplication\n",
    "\n",
    "PyTorch implements matrix multiplication functionality in the `torch.matmul()` method.\n",
    "\n",
    "1.  The inner dimensions must match:\n",
    "\n",
    "        (3, 2) @ (3, 2) won't work\n",
    "        (2, 3) @ (3, 2) will work\n",
    "        (3, 2) @ (2, 3) will work\n",
    "\n",
    "2.  The resulting matrix has the shape of the outer dimensions:\n",
    "\n",
    "        (2, 3) @ (3, 2) -> (2, 2)\n",
    "        (3, 2) @ (2, 3) -> (3, 3)\n",
    "\n",
    "### 6.2 Element wise multiplication:\n",
    "\n",
    "PyTorch implements multiplication functionality in the `torch.mul()` or `*` method.\n",
    "\n",
    "        (3, 2) @ (2, 3) won't work\n",
    "        (2, 3) @ (3, 3) will work\n",
    "$$[m\\times n\\times o] * [p\\times q\\times r]=[m\\times n\\times o]\\text{ this will be the new shape}$$\n",
    "* Each tensor must have at least one dimension - no empty tensors.\n",
    "* Comparing the dimension sizes of the two tensors, **going from last to first:**\n",
    "    * Each dimension must be equal $m=p\\;, n=q,\\; o=r $, **or**\n",
    "    * One of the dimensions must be of size 1, $p=1\\;, q=1,\\; o=r=1 $**or**\n",
    "    * The dimension does not exist in one of the tensors $q=1,\\; o=r=1 $\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3]) 1\n",
      "Element-Wise-Multiplication tensor([1, 4, 9])\n",
      "Element-Wise-Multiplication: torch.mul() tensor([1, 4, 9])\n",
      "Matrix-Multiplication: tensor(14)\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.tensor([1, 2, 3])\n",
    "print(tensor.shape, tensor.ndim)\n",
    "element_wise_mul = (\n",
    "    tensor * tensor\n",
    ")  # Element wise multiplication: [1*1, 2*2, 3*3]=[1, 4, 9]\n",
    "print(\"Element-Wise-Multiplication\", element_wise_mul)\n",
    "print(\"Element-Wise-Multiplication: torch.mul()\", torch.mul(tensor, tensor))\n",
    "\n",
    "print(\"Matrix-Multiplication:\", torch.matmul(tensor, tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor_A: torch.Size([3, 2]) \t 2\n",
      "tensor_B: torch.Size([3, 2]) \t 2\n",
      "Element wise: tensor([[ 7., 20.],\n",
      "        [24., 44.],\n",
      "        [45., 72.]])\n",
      "Transpose: torch.Size([2, 3])\n",
      "mat: torch.Size([2, 2]) \n",
      "  tensor([[ 76., 103.],\n",
      "        [100., 136.]])\n",
      "mat: torch.Size([3, 3]) \n",
      "  tensor([[ 27.,  30.,  33.],\n",
      "        [ 61.,  68.,  75.],\n",
      "        [ 95., 106., 117.]])\n"
     ]
    }
   ],
   "source": [
    "# Shapes need to be in the right way\n",
    "tensor_A = torch.tensor([[1, 2], [3, 4], [5, 6]], dtype=torch.float32)\n",
    "\n",
    "tensor_B = torch.tensor([[7, 10], [8, 11], [9, 12]], dtype=torch.float32)\n",
    "print(f\"tensor_A: {tensor_A.shape} \\t {tensor_A.ndim}\")\n",
    "print(f\"tensor_B: {tensor_B.shape} \\t {tensor_B.ndim}\")\n",
    "\n",
    "print(\"Element wise:\", torch.mul(tensor_A, tensor_B))\n",
    "print(\"Transpose:\", tensor_A.T.shape)\n",
    "\n",
    "mat = torch.matmul(tensor_A.T, tensor_B)\n",
    "print(\"mat:\", mat.shape, \"\\n \", mat)\n",
    "mat_1 = torch.matmul(tensor_A, tensor_B.T)\n",
    "print(\"mat:\", mat_1.shape, \"\\n \", mat_1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Element wise Multiplication:\n",
    "\n",
    "- Each tensor must have at least one dimension - no empty tensors.\n",
    "- Comparing the dimension sizes of the two tensors, _going from last to first:_\n",
    "- - Each dimension must be equal, _or_\n",
    "- - One of the dimensions must be of size 1, _or_\n",
    "- - The dimension does not exist in one of the tensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.7220, 0.8217],\n",
      "         [0.7220, 0.8217],\n",
      "         [0.7220, 0.8217]],\n",
      "\n",
      "        [[0.7220, 0.8217],\n",
      "         [0.7220, 0.8217],\n",
      "         [0.7220, 0.8217]],\n",
      "\n",
      "        [[0.7220, 0.8217],\n",
      "         [0.7220, 0.8217],\n",
      "         [0.7220, 0.8217]],\n",
      "\n",
      "        [[0.7220, 0.8217],\n",
      "         [0.7220, 0.8217],\n",
      "         [0.7220, 0.8217]]])\n",
      "tensor([[[0.2612, 0.7375],\n",
      "         [0.2612, 0.7375],\n",
      "         [0.2612, 0.7375]],\n",
      "\n",
      "        [[0.2612, 0.7375],\n",
      "         [0.2612, 0.7375],\n",
      "         [0.2612, 0.7375]],\n",
      "\n",
      "        [[0.2612, 0.7375],\n",
      "         [0.2612, 0.7375],\n",
      "         [0.2612, 0.7375]],\n",
      "\n",
      "        [[0.2612, 0.7375],\n",
      "         [0.2612, 0.7375],\n",
      "         [0.2612, 0.7375]]])\n",
      "tensor([[[0.8328, 0.8444],\n",
      "         [0.8328, 0.8444],\n",
      "         [0.8328, 0.8444]],\n",
      "\n",
      "        [[0.8328, 0.8444],\n",
      "         [0.8328, 0.8444],\n",
      "         [0.8328, 0.8444]],\n",
      "\n",
      "        [[0.8328, 0.8444],\n",
      "         [0.8328, 0.8444],\n",
      "         [0.8328, 0.8444]],\n",
      "\n",
      "        [[0.8328, 0.8444],\n",
      "         [0.8328, 0.8444],\n",
      "         [0.8328, 0.8444]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.ones(4, 3, 2)\n",
    "b = a * torch.rand(2)  # 3rd & 2nd dims identical to a, dim 1 absent\n",
    "print(b)\n",
    "c = a * torch.rand(1, 2)  # 3rd dim = 1, 2nd dim identical to a\n",
    "print(c)\n",
    "d = a * torch.rand(1, 2)  # 3rd dim identical to a, 2nd dim = 1\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (3) must match the size of tensor b (4) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m a \u001b[39m=\u001b[39m     torch\u001b[39m.\u001b[39mones(\u001b[39m4\u001b[39m, \u001b[39m3\u001b[39m, \u001b[39m2\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m b \u001b[39m=\u001b[39m a \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39mrand(\u001b[39m4\u001b[39m, \u001b[39m2\u001b[39m)    \u001b[39m# dimensions must match last-to-first\u001b[39;00m\n\u001b[1;32m      5\u001b[0m c \u001b[39m=\u001b[39m a \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39mrand(   \u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m) \u001b[39m# both 3rd & 2nd dims different\u001b[39;00m\n\u001b[1;32m      7\u001b[0m d \u001b[39m=\u001b[39m a \u001b[39m*\u001b[39m torch\u001b[39m.\u001b[39mrand((\u001b[39m0\u001b[39m, ))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (3) must match the size of tensor b (4) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "a = torch.ones(4, 3, 2)\n",
    "\n",
    "b = a * torch.rand(4, 2)  # dimensions must match last-to-first\n",
    "\n",
    "c = a * torch.rand(2, 3)  # both 3rd & 2nd dims different\n",
    "\n",
    "d = a * torch.rand((0,))  # can't broadcast with an empty tensor"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 More Math with Tensors\n",
    "\n",
    "PyTorch tensors have over three hundred operations that can be performed on them.\n",
    "\n",
    "Here is a small sample from some of the major categories of operations:\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3.1 Common Function:\n",
    "\n",
    "1. `torch.abs(x):` computes the element-wise absolute value of a tensor\n",
    "1. `torch.ceil(x):` rounds each element of a tensor upward to the nearest integer.\n",
    "1. `torch.floor(x):`rounds each element of a tensor downward to the nearest integer.\n",
    "1. `torch.clamp(x,min, max):` clamps each element of a tensor to a specified range defined by a minimum and maximum value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common functions:\n",
      "tensor([[0.0110, 0.2285, 0.9767, 0.0476],\n",
      "        [0.4484, 0.8447, 0.1992, 0.9755]])\n",
      "tensor([[-0., -0., 1., -0.],\n",
      "        [1., -0., -0., 1.]])\n",
      "tensor([[-1., -1.,  0., -1.],\n",
      "        [ 0., -1., -1.,  0.]])\n",
      "tensor([[-0.0110, -0.2285,  0.5000, -0.0476],\n",
      "        [ 0.4484, -0.5000, -0.1992,  0.5000]])\n"
     ]
    }
   ],
   "source": [
    "# common functions\n",
    "a = torch.rand(2, 4) * 2 - 1\n",
    "print(\"Common functions:\")\n",
    "print(torch.abs(a))\n",
    "print(torch.ceil(a))\n",
    "print(torch.floor(a))\n",
    "print(torch.clamp(a, -0.5, 0.5))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3.2 Aggregation\n",
    "\n",
    "1. `min, max, mean, sum`\n",
    "2. `torch.argmax(x):`\n",
    "3. `torch.argmin(x):`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum: 0\n",
      "Maximum: 90\n",
      "Mean: 45.0\n",
      "Sum: 450\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(0, 100, 10)\n",
    "print(f\"Minimum: {x.min()}\")\n",
    "print(f\"Maximum: {x.max()}\")\n",
    "# print(f\"Mean: {x.mean()}\") # this will error\n",
    "print(f\"Mean: {x.type(torch.float32).mean()}\")  # won't work without float datatype\n",
    "print(f\"Sum: {x.sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor: tensor([10, 20, 30, 40, 50, 60, 70, 80, 90])\n",
      "Index where max value occurs: 8\n",
      "Index where min value occurs: 0\n"
     ]
    }
   ],
   "source": [
    "# Create a tensor\n",
    "tensor = torch.arange(10, 100, 10)\n",
    "print(f\"Tensor: {tensor}\")\n",
    "\n",
    "# Returns index of max and min values\n",
    "print(f\"Index where max value occurs: {tensor.argmax()}\")\n",
    "print(f\"Index where min value occurs: {tensor.argmin()}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a small sample of For more details and the full inventory of math functions, have a look at the [documentation](https://pytorch.org/docs/stable/torch.html#math-operations).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # trigonometric functions and their inverses\n",
    "# angles = torch.tensor([0, math.pi / 4, math.pi / 2, 3 * math.pi / 4])\n",
    "# sines = torch.sin(angles)\n",
    "# inverses = torch.asin(sines)\n",
    "# print('\\nSine and arcsine:')\n",
    "# print(angles)\n",
    "# print(sines)\n",
    "# print(inverses)\n",
    "\n",
    "# # bitwise operations\n",
    "# print('\\nBitwise XOR:')\n",
    "# b = torch.tensor([1, 5, 11])\n",
    "# c = torch.tensor([2, 7, 10])\n",
    "# print(torch.bitwise_xor(b, c))\n",
    "\n",
    "# # comparisons:\n",
    "# print('\\nBroadcasted, element-wise equality comparison:')\n",
    "# d = torch.tensor([[1., 2.], [3., 4.]])\n",
    "# e = torch.ones(1, 2)  # many comparison ops support broadcasting!\n",
    "# print(torch.eq(d, e)) # returns a tensor of type bool\n",
    "\n",
    "# # reductions:\n",
    "# print('\\nReduction ops:')\n",
    "# print(torch.max(d))        # returns a single-element tensor\n",
    "# print(torch.max(d).item()) # extracts the value from the returned tensor\n",
    "# print(torch.mean(d))       # average\n",
    "# print(torch.std(d))        # standard deviation\n",
    "# print(torch.prod(d))       # product of all numbers\n",
    "# print(torch.unique(torch.tensor([1, 2, 1, 2, 1, 2]))) # filter unique elements\n",
    "\n",
    "# # vector and linear algebra operations\n",
    "# v1 = torch.tensor([1., 0., 0.])         # x unit vector\n",
    "# v2 = torch.tensor([0., 1., 0.])         # y unit vector\n",
    "# m1 = torch.rand(2, 2)                   # random matrix\n",
    "# m2 = torch.tensor([[3., 0.], [0., 3.]]) # three times identity matrix\n",
    "\n",
    "# print('\\nVectors & Matrices:')\n",
    "# print(torch.cross(v2, v1)) # negative of z unit vector (v1 x v2 == -v2 x v1)\n",
    "# print(m1)\n",
    "# m3 = torch.matmul(m1, m2)\n",
    "# print(m3)                  # 3 times m1\n",
    "# print(torch.svd(m3))       # singular value decomposition"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [7. Manipulating Tensor Shapes:](#h_cell)\n",
    "<a id='mts_cell'></a>\n",
    "\n",
    "1. `torch.reshape(input, shape):` Reshapes input to shape (if compatible) and explicitly create a new tensor with a modified shape or rearranged memory layout\n",
    "2. `torch.Tensor.view(shape):`Returns a view of the original tensor in a different shape but shares the same data as the original tensor.\n",
    "3. `torch.stack(tensors, dim=0):`Concatenates a sequence of tensors along a new dimension (dim), all tensors must be same size.\n",
    "4. `torch.squeeze(input):` Squeezes input to remove all the dimenions with value 1.\n",
    "5. `torch.unsqueeze(input, dim):`Returns input with a dimension value of 1 added at dim.\n",
    "6. `torch.permute(input, dims):`Returns a view of the original input with its dimensions permuted (rearranged) to dims.\n",
    "7. Altering Orginal Tensor:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.2103, 0.5611, 0.6405,  ..., 0.5529, 0.1800, 0.6779],\n",
       "         [0.9662, 0.9604, 0.1740,  ..., 0.3192, 0.9305, 0.4690]]),\n",
       " torch.Size([2, 2352]),\n",
       " 2352,\n",
       " tensor([0.2103, 0.5611, 0.6405,  ..., 0.3192, 0.9305, 0.4690]),\n",
       " torch.Size([4704]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshape\n",
    "image=torch.rand(2,3,28,28)\n",
    "reshape1=image.reshape(image.shape[0],-1) #flatten the image\n",
    "reshape2=image.reshape(-1)\n",
    "reshape1, reshape1.shape,3*28*28, reshape2, reshape2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When it can, `reshape()` will return a _view_ on the tensor to be changed - that is, a separate tensor object looking at the same underlying region of memory. _This is important:_ That means any change made to the source tensor will be reflected in the view on that tensor, unless you `clone()` it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6]])\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4],\n",
      "        [5],\n",
      "        [6]])\n"
     ]
    }
   ],
   "source": [
    "# view:\n",
    "# Create a 2x3 tensor\n",
    "original_tensor = torch.tensor([[1, 2, 3], [4, 5, 6]])\n",
    "\n",
    "# Reshape the tensor to be 3x2\n",
    "reshaped_tensor = original_tensor.view(6, 1)\n",
    "\n",
    "print(original_tensor)\n",
    "print(reshaped_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 2],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n"
     ]
    }
   ],
   "source": [
    "# Create three tensors\n",
    "tensor1 = torch.tensor([1, 2,2])\n",
    "tensor2 = torch.tensor([4, 5, 6])\n",
    "tensor3 = torch.tensor([7, 8, 9])\n",
    "\n",
    "# Stack them along a new dimension (default is dim=0)\n",
    "stacked_tensor = torch.stack([tensor1, tensor2, tensor3])\n",
    "\n",
    "print(stacked_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0,  1],\n",
      "         [ 2,  3],\n",
      "         [ 4,  5],\n",
      "         [ 6,  7]],\n",
      "\n",
      "        [[ 8,  9],\n",
      "         [10, 11],\n",
      "         [12, 13],\n",
      "         [14, 15]],\n",
      "\n",
      "        [[16, 17],\n",
      "         [18, 19],\n",
      "         [20, 21],\n",
      "         [22, 23]]]) torch.Size([3, 4, 2])\n",
      "tensor([[[ 0,  1],\n",
      "         [ 8,  9],\n",
      "         [16, 17]],\n",
      "\n",
      "        [[ 2,  3],\n",
      "         [10, 11],\n",
      "         [18, 19]],\n",
      "\n",
      "        [[ 4,  5],\n",
      "         [12, 13],\n",
      "         [20, 21]],\n",
      "\n",
      "        [[ 6,  7],\n",
      "         [14, 15],\n",
      "         [22, 23]]]) torch.Size([4, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "# permute\n",
    "original_tensor = torch.arange(24).reshape(3, 4, 2)\n",
    "\n",
    "# Permute the dimensions to change the order\n",
    "permuted_tensor = original_tensor.permute(1, 0, 2)\n",
    "\n",
    "print(original_tensor, original_tensor.shape)  # Output: torch.Size([3, 4, 2])\n",
    "print(permuted_tensor,permuted_tensor.shape)  # Output: torch.Size([2, 3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3., 4., 5., 6., 7.]) torch.Size([7])\n",
      "reshape(): tensor([[1., 2., 3., 4., 5., 6., 7.]]) torch.Size([1, 7])\n",
      "after reshape- X: tensor([1., 2., 3., 4., 5., 6., 7.]) torch.Size([7])\n",
      "reshape(): tensor([[  1., 200.,   3.,   4.,   5.,   6.,   7.]]) torch.Size([1, 7])\n",
      "after reshape- X: tensor([  1., 200.,   3.,   4.,   5.,   6.,   7.]) torch.Size([7])\n",
      "using view:\n",
      "view(): tensor([[1., 2., 3., 4., 5., 6., 7.]]) torch.Size([1, 7])\n",
      "after view -> y: tensor([1., 2., 3., 4., 5., 6., 7.]) torch.Size([7])\n",
      "view(): tensor([[  1., 200.,   3.,   4.,   5.,   6.,   7.]]) torch.Size([1, 7])\n",
      "after view -> y: tensor([  1., 200.,   3.,   4.,   5.,   6.,   7.]) torch.Size([7])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.arange(1.0, 8.0)\n",
    "y = torch.arange(1.0, 8.0)\n",
    "\n",
    "print(x, x.shape)\n",
    "x_reshaped = x.reshape(1, 7)\n",
    "print(\"reshape():\", x_reshaped, x_reshaped.shape)\n",
    "print(\"after reshape- X:\", x, x.shape)\n",
    "x_reshaped[:, 1] = 200\n",
    "print(\"reshape():\", x_reshaped, x_reshaped.shape)\n",
    "print(\"after reshape- X:\", x, x.shape)\n",
    "\n",
    "print(\"using view:\")\n",
    "z_viewed = y.view(1, 7)\n",
    "print(\"view():\", z_viewed, z_viewed.shape)\n",
    "print(\"after view -> y:\", y, y.shape)\n",
    "z_viewed[:, 1] = 200\n",
    "print(\"view():\", z_viewed, z_viewed.shape)\n",
    "print(\"after view -> y:\", y, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
      "        [1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
      "        [1, 2, 3, 4, 5, 6, 7, 8, 9]]) torch.Size([3, 9])\n"
     ]
    }
   ],
   "source": [
    "### stack(input,dimen)\n",
    "a = torch.arange(1, 10, 1)\n",
    "b = torch.rand(2, 2)\n",
    "# a_stack= torch.stack([a,a,b], dim=0) #tack expects each tensor to be equal size, but got [9] at entry 0 and [2, 2] at entry 2\n",
    "a_stack = torch.stack([a, a, a], dim=0)\n",
    "print(a_stack, a_stack.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor: tensor([[[ 1,  2, 33,  4,  5]]])\t  shape: torch.Size([1, 1, 5])\n",
      "\n",
      "New tensor: tensor([[ 1,  2, 33,  4,  5]])\t New shape: torch.Size([1, 5])\n",
      "\n",
      "New tensor: tensor([ 1,  2, 33,  4,  5])\t New shape: torch.Size([5])\n",
      "\n",
      "Unsques-1 tensor: tensor([[ 1,  2, 33,  4,  5]])\t New shape: torch.Size([1, 5])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[[1, 2, 33, 4, 5]]])\n",
    "print(f\"tensor: {a}\\t  shape: {a.shape}\")\n",
    "\n",
    "# Remove extra dimension from a\n",
    "a_squeezed = a.squeeze(dim=1)\n",
    "print(f\"\\nNew tensor: {a_squeezed}\\t New shape: {a_squeezed.shape}\")\n",
    "a_squeezed = torch.squeeze(a_squeezed)\n",
    "print(f\"\\nNew tensor: {a_squeezed}\\t New shape: {a_squeezed.shape}\")\n",
    "\n",
    "a_unsqueezed = a_squeezed.unsqueeze(dim=0)\n",
    "print(f\"\\nUnsques-1 tensor: {a_unsqueezed}\\t New shape: {a_unsqueezed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 226, 226])\n",
      "torch.Size([1, 3, 226, 226])\n"
     ]
    }
   ],
   "source": [
    "#unsqueeze\n",
    "a = torch.rand(3, 226, 226)\n",
    "b = a.unsqueeze(0)\n",
    "\n",
    "print(a.shape)\n",
    "print(b.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.7 Altering Tensors in Place\n",
    "\n",
    "Most binary operations on tensors will return a third, new tensor. When we say `c = a * b` (where `a` and `b` are tensors), the new tensor `c` will occupy a region of memory distinct from the other tensors.\n",
    "\n",
    "There are times, though, that you may wish to alter a tensor in place - for example, if you're doing an element-wise computation where you can discard intermediate values. For this, most of the math functions have a version with an appended underscore (`_`) that will alter a tensor in place.\n",
    "\n",
    "For example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before:\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n",
      "tensor([[0.8441, 0.9004],\n",
      "        [0.3995, 0.6324]])\n",
      "\n",
      "After adding:\n",
      "tensor([[1.8441, 1.9004],\n",
      "        [1.3995, 1.6324]])\n",
      "tensor([[1.8441, 1.9004],\n",
      "        [1.3995, 1.6324]])\n",
      "tensor([[0.8441, 0.9004],\n",
      "        [0.3995, 0.6324]])\n",
      "\n",
      "After multiplying\n",
      "tensor([[0.7125, 0.8107],\n",
      "        [0.1596, 0.3999]])\n",
      "tensor([[0.7125, 0.8107],\n",
      "        [0.1596, 0.3999]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(2, 2)\n",
    "b = torch.rand(2, 2)\n",
    "\n",
    "print(\"Before:\")\n",
    "print(a)\n",
    "print(b)\n",
    "print(\"\\nAfter adding:\")\n",
    "print(a.add_(b))\n",
    "print(a)\n",
    "print(b)\n",
    "print(\"\\nAfter multiplying\")\n",
    "print(b.mul_(b))\n",
    "print(b)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that these in-place arithmetic functions are methods on the `torch.Tensor` object, not attached to the `torch` module like many other functions (e.g., `torch.sin()`). As you can see from `a.add_(b)`, _the calling tensor is the one that gets changed in place._\n",
    "\n",
    "There is another option for placing the result of a computation in an existing, allocated tensor. Many of the methods and functions we've seen so far - including creation methods! - have an `out` argument that lets you specify a tensor to receive the output. If the `out` tensor is the correct shape and `dtype`, this can happen without a new memory allocation:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1.0902, 0.5189],\n",
      "        [0.2020, 0.1123]])\n",
      "tensor([[0.1779, 0.7497],\n",
      "        [0.9760, 0.5971]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(2, 2)\n",
    "b = torch.rand(2, 2)\n",
    "c = torch.zeros(2, 2)\n",
    "old_id = id(c)\n",
    "\n",
    "print(c)\n",
    "d = torch.matmul(a, b, out=c)\n",
    "print(c)  # contents of c have changed\n",
    "\n",
    "assert (\n",
    "    c is d\n",
    "), \"Not equal\"  # test c & d are same object, not just containing equal values\n",
    "assert id(c), old_id  # make sure that our new c is the same object as the old one\n",
    "\n",
    "torch.rand(2, 2, out=c)  # works for creation too!\n",
    "print(c)  # c has changed again\n",
    "assert id(c), old_id  # still the same object!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7.8 Copying Tensors\n",
    "\n",
    "As with any object in Python, assigning a tensor to a variable makes the variable a _label_ of the tensor, and does not copy it. For example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  1., 561.],\n",
      "        [  1.,   1.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(2, 2)\n",
    "b = a\n",
    "\n",
    "a[0][1] = 561  # we change a...\n",
    "print(b)  # ...and b is also altered"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what if you want a separate copy of the data to work on? The `clone()` method is there for you:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[True, True],\n",
      "        [True, True]])\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(2, 2)\n",
    "b = a.clone()\n",
    "\n",
    "assert b is not a  # different objects in memory...\n",
    "print(torch.eq(a, b))  # ...but still with the same contents!\n",
    "\n",
    "a[0][1] = 561  # a changes...\n",
    "print(b)  # ...but b is still all ones"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**There is an important thing to be aware of when using `clone()`.** If your source tensor has autograd, enabled then so will the clone.\n",
    "\n",
    "_In many cases, this will be what you want._ For example, if your model has multiple computation paths in its `forward()` method, and _both_ the original tensor and its clone contribute to the model's output, then to enable model learning you want autograd turned on for both tensors. If your source tensor has autograd enabled (which it generally will if it's a set of learning weights or derived from a computation involving the weights), then you'll get the result you want.\n",
    "\n",
    "On the other hand, if you're doing a computation where _neither_ the original tensor nor its clone need to track gradients, then as long as the source tensor has autograd turned off, you're good to go.\n",
    "\n",
    "_There is a third case,_ though: Imagine you're performing a computation in your model's `forward()` function, where gradients are turned on for everything by default, but you want to pull out some values mid-stream to generate some metrics. In this case, you _don't_ want the cloned copy of your source tensor to track gradients - performance is improved with autograd's history tracking turned off. For this, you can use the `.detach()` method on the source tensor:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5461, 0.5396],\n",
      "        [0.3053, 0.1973]], requires_grad=True)\n",
      "tensor([[0.5461, 0.5396],\n",
      "        [0.3053, 0.1973]], grad_fn=<CloneBackward>)\n",
      "tensor([[0.5461, 0.5396],\n",
      "        [0.3053, 0.1973]])\n",
      "tensor([[0.5461, 0.5396],\n",
      "        [0.3053, 0.1973]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(2, 2, requires_grad=True)  # turn on autograd\n",
    "print(a)\n",
    "\n",
    "b = a.clone()\n",
    "print(b)\n",
    "\n",
    "c = a.detach().clone()\n",
    "print(c)\n",
    "\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's happening here?\n",
    "\n",
    "- We create `a` with `requires_grad=True` turned on. **We haven't covered this optional argument yet, but will during the unit on autograd.**\n",
    "- When we print `a`, it informs us that the property `requires_grad=True` - this means that autograd and computation history tracking are turned on.\n",
    "- We clone `a` and label it `b`. When we print `b`, we can see that it's tracking its computation history - it has inherited `a`'s autograd settings, and added to the computation history.\n",
    "- We clone `a` into `c`, but we call `detach()` first.\n",
    "- Printing `c`, we see no computation history, and no `requires_grad=True`.\n",
    "\n",
    "The `detach()` method _detaches the tensor from its computation history._ It says, \"do whatever comes next as if autograd was off.\" It does this _without_ changing `a` - you can see that when we print `a` again at the end, it retains its `requires_grad=True` property."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [8. Tensor Accessing](#h_cell)\n",
    "<a id='aa_cell'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [9. Important Methods:](#h_cell)\n",
    "<a id='im_cell'></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [10. Moving to GPU](#h_cell)\n",
    "<a id='gpu_cell'></a>\n",
    "\n",
    "One of the major advantages of PyTorch is its robust acceleration on CUDA-compatible Nvidia GPUs. (\"CUDA\" stands for _Compute Unified Device Architecture_, which is Nvidia's platform for parallel computing.)\n",
    "\n",
    "First, we should check whether a GPU is available, with the `is_available()` method.\n",
    "\n",
    "**Note: If you do not have a CUDA-compatible GPU and CUDA drivers installed, the executable cells in this section will not execute any GPU-related code.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorry, CPU only.\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"We have a GPU!\")\n",
    "else:\n",
    "    print(\"Sorry, CPU only.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n",
      "tensor([[0.3285, 0.5655],\n",
      "        [0.0065, 0.7765]])\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    my_device = torch.device(\"cuda\")\n",
    "else:\n",
    "    my_device = torch.device(\"cpu\")\n",
    "print(\"Device: {}\".format(my_device))\n",
    "\n",
    "x = torch.rand(2, 2, device=my_device)\n",
    "print(x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have an existing tensor living on one device, you can move it to another with the `to()` method. The following line of code creates a tensor on CPU, and moves it to whichever device handle you acquired in the previous cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.rand(2, 2)\n",
    "y = y.to(my_device)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to know that in order to do computation involving two or more tensors, _all of the tensors must be on the same device_. The following code will throw a runtime error, regardless of whether you have a GPU device available:\n",
    "\n",
    "```\n",
    "x = torch.rand(2, 2)\n",
    "y = torch.rand(2, 2, device='gpu')\n",
    "z = x + y  # exception will be thrown\n",
    "```\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [11. NumPy Bridge](#h_cell)\n",
    "<a id='npb_cell'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]]\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "numpy_array = np.ones((2, 3))\n",
    "print(numpy_array)\n",
    "\n",
    "pytorch_tensor = torch.from_numpy(numpy_array)\n",
    "print(pytorch_tensor)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch creates a tensor of the same shape and containing the same data as the NumPy array, going so far as to keep NumPy's default 64-bit float data type.\n",
    "\n",
    "The conversion can just as easily go the other way:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5647, 0.9160, 0.7783],\n",
      "        [0.8277, 0.4579, 0.6382]])\n",
      "[[0.5646949  0.91600937 0.77828014]\n",
      " [0.82769746 0.45785618 0.6381657 ]]\n"
     ]
    }
   ],
   "source": [
    "pytorch_rand = torch.rand(2, 3)\n",
    "print(pytorch_rand)\n",
    "\n",
    "numpy_rand = pytorch_rand.numpy()\n",
    "print(numpy_rand)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to know that these converted objects are using _the same underlying memory_ as their source objects, meaning that changes to one are reflected in the other:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  1.,  1.],\n",
      "        [ 1., 23.,  1.]], dtype=torch.float64)\n",
      "[[ 0.5646949   0.91600937  0.77828014]\n",
      " [ 0.82769746 17.          0.6381657 ]]\n"
     ]
    }
   ],
   "source": [
    "numpy_array[1, 1] = 23\n",
    "print(pytorch_tensor)\n",
    "\n",
    "pytorch_rand[1, 1] = 17\n",
    "print(numpy_rand)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
